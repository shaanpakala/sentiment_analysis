{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ba717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = '/Users/shaanpakala/Desktop/'\n",
    "root_path = f'{desktop_path}CS_STUFF/Python/NLP/Sentiment_Analysis/'\n",
    "data_path = f'{root_path}data/'\n",
    "saved_model_path = f'{root_path}saved_models/'\n",
    "train_vect_path = f'{root_path}train_vectors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234b6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'{data_path}yellowpages.txt', f'{data_path}yelp_reviews.txt', f'{data_path}kaggle_twitter.txt', \n",
    "         f'{data_path}kaggle_reddit.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileText():\n",
    "    text = []\n",
    "    for i in range(len(files)):\n",
    "\n",
    "        file = files[i]\n",
    "\n",
    "        f = open(file, encoding=\"utf8\")\n",
    "        t = f.read().split('\\n - \\n - \\n')\n",
    "        f.close()\n",
    "\n",
    "        if (i == 2): t = t[:20000]\n",
    "\n",
    "        elif (i == 3): t = t[:20000]\n",
    "\n",
    "        text+=t\n",
    "    \n",
    "        \n",
    "    return text[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ea9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "adverbs = ['very', 'too', 'really', 'extremely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89944fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomchars = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '&', ';', 'yyy', 'ooo', '\\\\', '.', '!', ':', '/',\n",
    "              '+', '-', '@', '*', '(', ')', '#', 'hhh', ',', '$', 'ðŸ˜‰', 'Ã³', 'Ã©', 'lll', '%', '_','uuu','ooo','sss',\n",
    "               'ppp', 'âœŒ', 'ðŸ¤¡', 'haha', 'lol', 'lmao', 'eee', 'Ä—', 'Ä¯', \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8328882",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = ['i', 'and', 'at', 'the', 'yet', 'so', 'because', 'on', 'of', 'to', 'as',' in', 'his', 'her', 'she', 'him',\n",
    "            'them', 'they', 'it', 'hers', 'their', 'its', 'theirs', 'with', 'said', 'for', 'after', 'will', 'that',\n",
    "            'about', 'who', 'by', 'all', 'where', 'over', 'year', 'years', 'continue', 'two', 'three', 'four', 'five',\n",
    "            'six', 'seven', 'eight', 'nine', 'ten', 'other', 'into', 'a', 'an', 'in', 'my', 'is', 'but', 'he', 'me',\n",
    "            'from', 'am', 'we', 'ok', 'okay', 'you', 'us', 'have', 'are', 'your', 'own', 'had', 'or', 'this', 'has',\n",
    "            'hella', 'yo', 'est', \"he's\", \"she's\", \"we're\", \"they're\", \"we'll\", \"they'll\", \"i'm\", \"that's\", \"who's\",\n",
    "            \"what\", \"when\", \"how\", \"it's\", \"i'll\", \"she'll\", \"he'll\", \"it'll\", \"that'll\", \"who'll\", \"might've\",\n",
    "            \"would've\", \"could've\", \"should've\", \"here's\", \"what's\", \"i've\", \"it'd\", \"we'd\", \"they'd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe591cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "negationWords = ['not', 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd35d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "negContractions = {\"shouldn't\":'should not', \"wouldn't\":\"would not\", \"cannot\":\"can not\", \"can't\":\"can not\",\n",
    "               \"aren't\":\"are not\", \"ain't\":\"is not\", \"don't\":\"do not\", \"couldn't\":\"could not\", \"haven't\":\"have not\",\n",
    "               \"needn't\":\"need not\", \"didn't\":\"did not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"won't\":\"will not\",\n",
    "               \"hasn't\":\"has not\", \"doesn't\":\"does not\", \"isn't\":\"is not\",\n",
    "                   \n",
    "                \"shouldnt\":'should not', \"wouldnt\":\"would not\", \"cant\":\"can not\",\n",
    "               \"arent\":\"are not\", \"aint\":\"is not\", \"dont\":\"do not\", \"couldnt\":\"could not\", \"havent\":\"have not\",\n",
    "               \"neednt\":\"need not\", \"didnt\":\"did not\", \"wasnt\":\"was not\", \"werent\":\"were not\", \"wont\":\"will not\",\n",
    "               \"hasnt\":\"has not\", \"doesnt\":\"does not\", \"isnt\":\"is not\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f914421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimWord(word):\n",
    "    w = word\n",
    "    \n",
    "    if ((w[len(w)-1] == \",\")or(w[len(w)-1] == \".\")or(w[len(w)-1] == \"?\")or(w[len(w)-1] == \"%\")\n",
    "        or(w[len(w)-1] == \"!\")or(w[len(w)-1] == \"â€™\")or(w[len(w)-1] == \":\")or(w[len(w)-1] == \")\")or(w[len(w)-1] == \";\")\n",
    "        or(w[len(w)-1]==\"\\\"\")or(w[len(w)-1]==\"-\")or(w[len(w)-1]==\"'\")or(w[len(w)-1]==\"â€\")or(w[len(w)-1]==\"â€˜\")\n",
    "        or(w[len(w)-1]==\"]\")or(w[len(w)-1]==\">\")):\n",
    "        w = w[:len(w)-1]          \n",
    "    elif((w[0]==\"'\")or(w[0]==\"â€™\")or(w[0]==\"\\\"\")or(w[0]==\"-\")or(w[0]==\"â€œ\")or(w[0]==\"(\")or(w[0]==\"â€˜\")\n",
    "        or(w[0]==\"[\")or(w[0]==\"â€\")):\n",
    "        w = w[1:]          \n",
    "    elif ((w[len(w)-2:len(w)] == \"â€™s\")or(w[len(w)-2:len(w)] == \"\\'s\")):\n",
    "        w = w[:len(w)-2]\n",
    "    else:\n",
    "        return w\n",
    "    \n",
    "    \n",
    "    return(trimWord(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38cc2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasVowel(word):\n",
    "    vowels = 'aeiouy'\n",
    "    \n",
    "    for i in word:\n",
    "        if (vowels.find(i) != -1): return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf86c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodWord(w):\n",
    "    \n",
    "    if (len(w) > 15): return False\n",
    "    \n",
    "    if (not hasVowel(w)): return False\n",
    "    \n",
    "    if (w in stopWords): return False\n",
    "    \n",
    "    for c in randomchars:\n",
    "        if (w.find(c)!=-1): return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a24c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_line = '_____________________________________________________________________________________________________________________'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59516b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_to_num(sentiment):\n",
    "    if(sentiment == 'negative'): return -1\n",
    "    elif(sentiment == 'neutral'): return 0\n",
    "    elif(sentiment == 'positive'): return 1\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab08e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_sentiment(num):\n",
    "    if(num == -1): return 'negative'\n",
    "    elif(num == 0): return 'neutral'\n",
    "    elif(num == 1): return 'positive'\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3f2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text, w_d):\n",
    "    vector = [0 for x in range(len(w_d))]\n",
    "    \n",
    "    words = text.split()\n",
    "    textLen = len(words)\n",
    "\n",
    "    for i in range(textLen):\n",
    "        try: word = trimWord(words[i]).lower()\n",
    "        except: continue\n",
    "        \n",
    "        if (not goodWord(word)): continue\n",
    "\n",
    "        if (word in negContractions): word = 'not'\n",
    "\n",
    "        if (word == 'not'): \n",
    "            try: \n",
    "                nextWord = trimWord(words[i+1]).lower()\n",
    "                if (not goodWord(nextWord)): continue\n",
    "                word = (f'{word}_{nextWord}')\n",
    "\n",
    "            except: continue\n",
    "\n",
    "        elif (word in adverbs): \n",
    "            try: \n",
    "                nextWord = trimWord(words[i+1]).lower()\n",
    "                if (not goodWord(nextWord)): continue\n",
    "                word = (f'{word}_{nextWord}')\n",
    "\n",
    "            except: continue\n",
    "\n",
    "        try: vector[word_dict.index(word)]+=1\n",
    "        except: continue\n",
    "    \n",
    "    length = sum(vector)\n",
    "    \n",
    "    try: new_vector = [(x / length) for x in vector]\n",
    "    except: return 0\n",
    "    \n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88495bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_from_sentence(text, clf, word_dict):\n",
    "    \n",
    "    vector = vectorize(text, word_dict)\n",
    "    vector_np = np.array(vector)\n",
    "    vector_torch = torch.tensor(vector_np)\n",
    "    single_vect_torch = vector_torch.unsqueeze(0)\n",
    "    prediction = int(classifier.predict(single_vect_torch))\n",
    "    \n",
    "    if (prediction == -1): sentiment = 'negative'\n",
    "    elif (prediction == 0): sentiment = 'neutral'\n",
    "    elif (prediction == 1): sentiment = 'positive'\n",
    "    else: sentiment = None\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a975458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(s, classifier, word_dict):\n",
    "    \n",
    "    try: class_ = classify_from_sentence(s, classifier, word_dict)        \n",
    "    except: return 'Error'\n",
    "        \n",
    "    party = s.split()[len(s.split())-1]\n",
    "    \n",
    "    if ((party == 'r') or (party == 'd')): return [class_, party]\n",
    "    \n",
    "    else: return class_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
